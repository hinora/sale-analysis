# Export Goods Analysis Application

A comprehensive data analysis platform for export/import transaction data with AI-powered insights using DeepSeek-R1.

## Features

- üìä **CSV Import**: Fast bulk import with duplicate detection and data validation
- üîç **Transaction Query**: Advanced filtering, sorting, and pagination
- üì¶ **Goods Catalog**: Product-centric view with aggregated statistics
- üè¢ **Company Dashboard**: Customer analytics with import metrics
- ü§ñ **AI Analysis**: Natural language queries powered by DeepSeek-R1 (1.5B for dev, 14B for production)
- ‚ö° **Background Jobs**: Asynchronous AI classification of imported goods

## Tech Stack

- **Frontend**: Next.js 16, React, Material-UI (MUI)
- **Backend**: Next.js API Routes, Node.js
- **Database**: MongoDB 7
- **AI**: Ollama with DeepSeek-R1 models
- **Deployment**: Docker Compose

## AI Models

This application uses DeepSeek-R1 models for AI-powered features:

- **Development**: `deepseek-r1:1.5b` (~1GB) - Fast, lightweight for local development
- **Production**: `deepseek-r1:8b` (~8GB) - More accurate, better reasoning for production use

### Model Configuration

The AI model is automatically selected based on the environment:

```bash
# Development (uses deepseek-r1:1.5b)
NODE_ENV=development

# Production (uses deepseek-r1:8b)
NODE_ENV=production
```

You can override the model by setting the `AI_MODEL` environment variable:

```bash
AI_MODEL=deepseek-r1:8b  # Force 14B model in development
AI_MODEL=deepseek-r1:1.5b # Force 1.5B model in production (not recommended)
```

## Quick Start

### Prerequisites

- Docker and Docker Compose
- 8GB+ RAM (16GB recommended for production)
- 10GB+ disk space (for models and data)

### Development Setup

1. **Clone the repository**:
```bash
git clone <repository-url>
cd sale-analysis
```

2. **Start all services** (development mode with 1.5B model):
```bash
docker-compose up -d
```

This will:
- Start Next.js app on port 3000
- Start MongoDB on port 27017  
- Start Ollama on port 11434
- Download DeepSeek-R1 1.5B model (~1GB, takes 1-2 minutes)

3. **Wait for model download**:
```bash
docker-compose logs -f ollama-setup
```

4. **Access the application**:
- App: http://localhost:3000
- MongoDB: mongodb://localhost:27017

### Production Setup

1. **Start production services** (with 14B model):
```bash
docker-compose -f docker-compose.prod.yml up -d
```

This will:
- Build optimized Next.js production bundle
- Download DeepSeek-R1 14B model (~8GB, takes 10-15 minutes)
- Configure production resource limits

2. **Monitor model download**:
```bash
docker-compose -f docker-compose.prod.yml logs -f ollama-setup
```

## Usage

### 1. Import CSV Data

1. Navigate to **Nh·∫≠p CSV** (Import CSV)
2. Upload your export transaction CSV file
3. Wait for processing (shows progress bar)
4. Review import summary

**Note**: Initial import uses fast fallback classification. AI classification runs automatically in the background every 5 minutes.

### 2. Query Transactions

1. Navigate to **Tra c·ª©u giao d·ªãch** (Transaction Query)
2. Apply filters:
   - Company name (partial match)
   - Date range
   - Category
   - Goods name
3. Sort by columns
4. Pagination (50 records per page)

### 3. Analyze Goods

1. Navigate to **Danh m·ª•c h√†ng h√≥a** (Goods Catalog)
2. View aggregated statistics per product
3. Click on any product to see transaction details

### 4. Company Dashboard

1. Navigate to **Ph√¢n t√≠ch c√¥ng ty** (Company Analysis)
2. View import statistics by company
3. Click on any company to see transaction breakdown

### 5. AI Analysis

1. Navigate to **AI Ph√¢n t√≠ch** (AI Analysis)
2. Select data filters (category, date range, company)
3. Click **"T·∫£i d·ªØ li·ªáu v√†o AI"** (Load Data to AI)
4. Wait for "S·∫µn s√†ng" (Ready) status
5. Ask questions in Vietnamese or English:
   - "C√¥ng ty n√†o nh·∫≠p kh·∫©u nhi·ªÅu nh·∫•t?" (Which company imports the most?)
   - "T·ªïng gi√° tr·ªã xu·∫•t kh·∫©u l√† bao nhi√™u?" (What's the total export value?)
   - "So s√°nh gi√° tr·ªã gi·ªØa c√°c danh m·ª•c" (Compare values between categories)

## Development

### Local Development (without Docker)

1. **Install dependencies**:
```bash
yarn install
```

2. **Set environment variables**:
```bash
cp .env.example .env.local
# Edit .env.local with your values
```

3. **Start MongoDB** (required):
```bash
docker-compose up mongodb -d
```

4. **Start Ollama** (required for AI features):
```bash
docker-compose up ollama -d
ollama pull deepseek-r1:1.5b
```

5. **Run development server**:
```bash
yarn dev
```

### Build for Production

```bash
yarn build
yarn start
```

## Project Structure

```
src/
‚îú‚îÄ‚îÄ components/          # React components
‚îÇ   ‚îú‚îÄ‚îÄ ai/             # AI analysis components
‚îÇ   ‚îú‚îÄ‚îÄ common/         # Shared components
‚îÇ   ‚îú‚îÄ‚îÄ import/         # CSV import components
‚îÇ   ‚îú‚îÄ‚îÄ layout/         # Layout components
‚îÇ   ‚îî‚îÄ‚îÄ tables/         # Data table components
‚îú‚îÄ‚îÄ lib/                # Backend utilities
‚îÇ   ‚îú‚îÄ‚îÄ ai/            # AI services (classifier, query handler)
‚îÇ   ‚îú‚îÄ‚îÄ csv/           # CSV processing
‚îÇ   ‚îú‚îÄ‚îÄ db/            # Database models and connection
‚îÇ   ‚îú‚îÄ‚îÄ jobs/          # Background jobs
‚îÇ   ‚îî‚îÄ‚îÄ utils/         # Helper functions
‚îú‚îÄ‚îÄ pages/             # Next.js pages and API routes
‚îÇ   ‚îú‚îÄ‚îÄ api/          # API endpoints
‚îÇ   ‚îî‚îÄ‚îÄ *.tsx         # Page components
‚îî‚îÄ‚îÄ styles/           # Global styles
```

## Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `NODE_ENV` | Environment mode | `development` |
| `MONGODB_URI` | MongoDB connection string | `mongodb://mongodb:27017/export-goods` |
| `OLLAMA_HOST` | Ollama API URL | `http://ollama:11434` |
| `AI_MODEL` | AI model name | Auto (1.5b dev, 14b prod) |
| `NEXT_TELEMETRY_DISABLED` | Disable Next.js telemetry | `1` |

### AI Model Selection Logic

```javascript
// Code automatically selects model based on environment
const model = process.env.AI_MODEL || 
  (process.env.NODE_ENV === "production" 
    ? "deepseek-r1:8b"    // Production: More accurate
    : "deepseek-r1:1.5b"); // Development: Faster
```

## Performance

### Import Speed

- **With fallback classification**: ~5,000 records/minute
- **Background AI classification**: ~10-50 goods/minute (depends on model)

### AI Query Response Time

- **1.5B model** (development): 2-5 seconds per query
- **14B model** (production): 5-15 seconds per query (more accurate)

### Resource Requirements

| Component | Development (1.5B) | Production (14B) |
|-----------|-------------------|------------------|
| App | 2GB RAM | 4GB RAM |
| MongoDB | 2GB RAM | 4GB RAM |
| Ollama | 4GB RAM | 16GB RAM |
| **Total** | **8GB RAM** | **24GB RAM** |

**GPU Support**: Highly recommended for production. Reduces AI response time by 10-20x.

## Troubleshooting

### Model Download Issues

```bash
# Check Ollama service logs
docker-compose logs ollama

# Manually pull model
docker exec -it export-goods-ollama ollama pull deepseek-r1:1.5b

# Verify models installed
docker exec -it export-goods-ollama ollama list
```

### AI Features Not Working

1. Verify Ollama is running: `curl http://localhost:11434`
2. Check model is downloaded: `docker exec -it export-goods-ollama ollama list`
3. View logs: `docker-compose logs app | grep AI`

### Database Connection Issues

```bash
# Check MongoDB is running
docker-compose ps mongodb

# Test connection
docker exec -it export-goods-mongodb mongosh --eval "db.adminCommand('ping')"
```

## License

[Add your license information here]

## Support

For issues and questions, please open an issue on the repository.
